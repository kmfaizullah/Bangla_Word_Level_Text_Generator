{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocess import Process\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, GRU, Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD, Adagrad, Adadelta, RMSprop, Adam\n",
    "from keras.models import model_from_json\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"./data/BanglaData/\"\n",
    "length=30\n",
    "checkpoint_path = \"cer_result_100_new.ckpt\"\n",
    "base_learning_rate=0.01\n",
    "epoch=150\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "process= Process(directory,length)\n",
    "sequences,mapping=process.encode_seq()\n",
    "vocab = len(mapping)\n",
    "sequences = np.array(sequences)\n",
    "# create X and y\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "# one hot encode y\n",
    "y = to_categorical(y, num_classes=vocab)\n",
    "# create train and validation sets\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print('Train shape:', X_tr.shape, 'Val shape:', X_val.shape)\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab, 50,embeddings_initializer='uniform', input_length=length, trainable=True))\n",
    "model.add(GRU(150, recurrent_dropout=0.1, dropout=0.3))\n",
    "model.add(Dense(vocab, activation='softmax'))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Set Optimizer\n",
    "opt = SGD(lr=1e-2, decay=1e-2/100)\n",
    "#opt = Adam(lr=1e-2)\n",
    "\n",
    "# Compile model\n",
    "#model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=opt)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_tr, y_tr,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epoch,\n",
    "                verbose=1,\n",
    "                initial_epoch=0,\n",
    "                validation_data=(X_val, y_val),\n",
    "                     callbacks = [cp_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "    inp=seed_text\n",
    "    inp1=[]\n",
    "    inp1.append(inp)\n",
    "    inp = inp.split()\n",
    "    for _ in range(n_chars):\n",
    "        encoded = [mapping[char] for char in inp]\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        yhat\n",
    "        for char, index in mapping.items():\n",
    "            if index == yhat:\n",
    "                inp.append(char)\n",
    "                inp1.append(\" \"+char)\n",
    "    data_new = ''.join(str(e) for e in inp1)\n",
    "\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'বাংলা আমার কখনো দুটো একই অর্থে প্রয়োগ করা হয়'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp=\"বাংলা আমার\"\n",
    "generate_seq(model, mapping, 30, inp,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
